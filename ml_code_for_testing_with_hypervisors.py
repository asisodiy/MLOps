# -*- coding: utf-8 -*-
"""ML code for testing with hypervisors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eWqnn4U0x8wvI8oIrY8srBz_YgQzdNv6
"""

#IMPORTING THE PANDAS LIBRARY

import pandas as pd

# DEFINING OUR DATA AS DATASET NAME 

dataset = pd.read_csv('Churn_Modelling.csv')

# IT SHOWS NO OF COLUMNS IN OUR DATASET

dataset.columns

# TELLING WHAT IS OUR PREDICTOR THAT IS ** Y ** IN OUR DATASET 

y = dataset['Exited']



# TELLING WHAT IS OUR PREDICT  THAT IS ** X ** IN OUR DATASET

X = dataset[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',
       'IsActiveMember', 'EstimatedSalary']]

# FROM HERE WE START DATA PREPROCESSING AND DATA CLEANING TYPICALLY KNOW AS DATA MINING

geo = dataset['Geography']

# CREATING DUMMY VARIABLES

geo = pd.get_dummies(geo, drop_first=True )

gender = dataset['Gender']

gender = pd.get_dummies(gender, drop_first=True )

# NOW APPENDING THE DUMMY VARIABLE CREATED IN THE DATASET....

X = pd.concat([X,gender,geo], axis=1)

X.info()

# NOW FROM HERE WE START OUR MODEL TRAINING AND  MODEL SELECTION 

from keras.optimizers import Adam

#SPLITTING THE DATA FOR THE PURPOSE OF TRAINING AND TESTING PART....
# BUDDY IF U WANT TO REDUCE THE TIME OF TRAINING FOR THE TESTING PURPOSE THEN JUST INCREASE THE THE RATIO FOR THER TRAINING AND TESTING DATA.....

from sklearn.model_selection import train_test_split

# HERE AS U SEE THE TEST SIZE IS PUT 20%... FOR THE BASIC TESTING AND FAST PROCESSING U MAY CHANGE IT MANULLY FOR NOW TIMES.....

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

from keras.models import Sequential

# SO HERE WE CHOOSE THE SEQUENTIAL MODEL FOR THE PURPOSE OF MODEL TRAINING....

model = Sequential()

from keras.layers import Dense

# VARIABLE  HYPERVISOR = HY1 , HY2 , HY3, HY4 
# VARIABLE EPOCHS = EPOCHS1
# THE ABOVE LISTED ARE THE HYPERVISORS THAT U NEED TO CHANGE IN THE MODEL TRAINING.....
#

# DO THREE RUNS FOR THE PURPOSE OF TESTING PART
# FOR RUN 1  =>  HY1 = 6  ,  HY2 = 6  ,   HY3 = 6 ,  EPOCHS1 = 150
# FOR RUN 2 =>
HY1 = 7   
HY2 = 7     
HY3 = 7  
EPOCHS1 = 200
# FOR RUN 3  =>  HY1 = 8  ,  HY2 = 8  ,   HY3 = 8 ,  EPOCHS1 = 250

model.add(Dense(units= HY1 , input_dim=11, activation='relu' ))

model.add(Dense(units= HY2, activation='relu'))

model.add(Dense(units= HY3, activation='relu'))

model.add(Dense(units= 1 ,  activation='sigmoid' ))

model.compile(optimizer=Adam(learning_rate=0.000001),loss='binary_crossentropy' ,metrics=['accuracy'] )

model.fit(X_train,y_train , epochs= EPOCHS1 , verbose=0)

df_loss = pd.DataFrame(model.history.history)

# THIS WHOLE CODE WILL GIVE U THE ACCURACY OF THE MODEL WHICH IS THE OUTPUT OF THE CODE.....
# FROM THAT U WILL GET TO KNOW WHAT IS THE ACCURACY OF THE MODEL THAT WE ARE TRAINING RIGHT NOW.....

import numpy
cvscores = []
scores = model.evaluate(X_test, y_test, verbose=0)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvscores), numpy.std(cvscores)))

# THIS ISJUST THE GRAPH OF THE LOSS THAT SHOWS THE LOSS PATTERN IN THE MODEL..
# A MODEL IS SSAID TO BE GOOD IF THE LOSS AT THE END OF THE MODEL IS VERY LESS...
# LESSER THE LOSS BETTER WILL BE THE MODEL HENCE PRECISE ACCURACY.....


df_loss.plot()

